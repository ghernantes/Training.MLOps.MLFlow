{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a2008fa7",
   "metadata": {},
   "source": [
    "# 1. Running and tracking machine learning experiments"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "36be61d6",
   "metadata": {},
   "source": [
    "## 1.0. The data we use: Palmer Pinguins\n",
    "\n",
    "Data were collected and made available by Dr. Kristen Gorman and the Palmer Station, Antarctica LTER, a member of the Long Term Ecological Research Network. It provides a great dataset for data exploration & visualization, as an alternative to iris.\n",
    "\n",
    "We will use this dataset in classification setting to predict the penguins’ species from anatomical information.\n",
    "\n",
    "Each penguin is from one of the three following species: Adelie, Gentoo, and Chinstrap.\n",
    "\n",
    "<!-- ![palmer penguins](../img/palmer_penguins.png \"Palmer Penguins\") -->\n",
    "<img src='../img/palmer_penguins.png' alt='' width='600'>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "706b6ce1",
   "metadata": {},
   "source": [
    "This problem is a classification problem since the target is categorical. We will use features based on penguins’ culmen measurement.\n",
    "\n",
    "<!-- ![Culmen features](../img/culmen_depth.png) -->\n",
    "<img src='../img/culmen_depth.png' alt='' width='600'>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1dee973",
   "metadata": {},
   "source": [
    "## 1.1. Load and prepare the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5501ff60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Culmen Length (mm)</th>\n",
       "      <th>Culmen Depth (mm)</th>\n",
       "      <th>Species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>36.2</td>\n",
       "      <td>16.1</td>\n",
       "      <td>Adelie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>41.6</td>\n",
       "      <td>18.0</td>\n",
       "      <td>Adelie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>36.4</td>\n",
       "      <td>17.0</td>\n",
       "      <td>Adelie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>34.4</td>\n",
       "      <td>18.4</td>\n",
       "      <td>Adelie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>42.0</td>\n",
       "      <td>19.5</td>\n",
       "      <td>Adelie</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Culmen Length (mm)  Culmen Depth (mm) Species\n",
       "77                36.2               16.1  Adelie\n",
       "64                41.6               18.0  Adelie\n",
       "33                36.4               17.0  Adelie\n",
       "17                34.4               18.4  Adelie\n",
       "52                42.0               19.5  Adelie"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "culmen_columns = [\"Culmen Length (mm)\", \"Culmen Depth (mm)\"]\n",
    "target_column = \"Species\"\n",
    "\n",
    "data_path = \"../data/penguins_classification.csv\"\n",
    "data = pd.read_csv(data_path)\n",
    "\n",
    "data.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "757404bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "data, target = data[culmen_columns], data[target_column]\n",
    "data_train, data_test, target_train, target_test = train_test_split(data, target, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b33dd0e",
   "metadata": {},
   "source": [
    "## 1.2. The modelling: Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d9daa4c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeClassifier(max_depth=3, max_leaf_nodes=4)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier(max_depth=3, max_leaf_nodes=4)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "DecisionTreeClassifier(max_depth=3, max_leaf_nodes=4)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "tree = DecisionTreeClassifier(max_depth=3, max_leaf_nodes=4)\n",
    "tree.fit(data_train, target_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "55f76a53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the DecisionTreeClassifier: 96.5%\n"
     ]
    }
   ],
   "source": [
    "test_score = tree.score(data_test, target_test)\n",
    "print(f\"Accuracy of the DecisionTreeClassifier: {test_score:.1%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd3780fd",
   "metadata": {},
   "source": [
    "## 1.3. MLflow Stores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cded149",
   "metadata": {},
   "source": [
    "### Tracking stores\n",
    "\n",
    "MLflow supports two types of backend stores: file store and database-backed store.\n",
    "\n",
    "- Local file path (specified as file:/my/local/dir), where data is just directly stored locally. Defaults to `mlruns/`.\n",
    "- Database encoded as +://:<password>@:/. Mlflow supports the dialects mysql, mssql, sqlite, and postgresql. For more details, see SQLAlchemy database uri.\n",
    "- HTTP server (specified as https://my-server:5000), which is a server hosting an MLFlow tracking server.\n",
    "- Databricks workspace (specified as databricks or as databricks://, a Databricks CLI profile.)\n",
    "\n",
    "### Artifact stores\n",
    "Where you store models, plots and other stuff.\n",
    "\n",
    "- Amazon S3\n",
    "- Azure Blob Storage\n",
    "- Google Cloud Storage\n",
    "- FTP server\n",
    "- SFTP Server\n",
    "- NFS\n",
    "- HDFS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98893984",
   "metadata": {},
   "source": [
    "## 1.4. Setup and configure the tracking server"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "150febdf",
   "metadata": {},
   "source": [
    "We want to use a database as a tracking store and a local directory as artifact store.\n",
    "Using a database is required for later steps in the tutorial, like managing deployments. In this case, artifacts are stored under the local ./mlruns directory, and MLflow entities are inserted in a SQLite database file mlruns.db.\n",
    "\n",
    "\n",
    "![tracking setup](../img/tracking_setup.png)\n",
    "\n",
    "\n",
    "Run to start the tracking server:\n",
    "\n",
    "```\n",
    "mlflow server --backend-store-uri sqlite:///mflow.db --default-artifact-root mlruns/ --host 0.0.0.0 --port 5000\n",
    "```\n",
    "\n",
    "in a terminal. Make sure you run it inside the virtual environment! Put `pipenv run` in front of it.\n",
    "\n",
    "Now you should be able to see the Tracking UI in a browser at `http://0.0.0.0:5000`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a947eab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import mlflow.sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "447b5615",
   "metadata": {},
   "outputs": [],
   "source": [
    "# local_server_uri = \"http://0.0.0.0:5000\"    # your local server URI\n",
    "remote_server_uri = \"http://localhost:5007\"   # your remote (local docker container in this example) server URI\n",
    "\n",
    "mlflow.set_tracking_uri(remote_server_uri)    # or set the MLFLOW_TRACKING_URI in the env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "36fa3afd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'http://localhost:5007'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlflow.tracking.get_tracking_uri()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e930ea21",
   "metadata": {},
   "source": [
    "### Create a new experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "21e087de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp_name = \"penguin_classification\"\n",
    "mlflow.create_experiment(exp_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77fc6a11",
   "metadata": {},
   "source": [
    "## 1.5. Add tracking code to the machine learning experiment above\n",
    "\n",
    "Basic things to track:\n",
    "- Parameters: Key-value input parameters: `mlflow.log_param, mlflow.log_params`\n",
    "- Metrics: Key-value metrics, where the value is numeric (can be updated over the run): `mlflow.log_metric, mlflow.log_metrics`"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0765bc20",
   "metadata": {},
   "source": [
    "Recall the following code from above:\n",
    "\n",
    "```python\n",
    "# Load dataset\n",
    "culmen_columns = [\"Culmen Length (mm)\", \"Culmen Depth (mm)\"]\n",
    "target_column = \"Species\"\n",
    "\n",
    "data_path = \"../data/penguins_classification.csv\"\n",
    "data = pd.read_csv(data_path)\n",
    "\n",
    "# Prepare a train-test-split\n",
    "data, target = data[culmen_columns], data[target_column]\n",
    "data_train, data_test, target_train, target_test = train_test_split(data, target, random_state=0)\n",
    "\n",
    "# Initialize and fit a classifier\n",
    "tree = DecisionTreeClassifier(max_depth=3, max_leaf_nodes=4)\n",
    "tree.fit(data_train, target_train)\n",
    "\n",
    "# Calculate test scores\n",
    "test_score = tree.score(data_test, target_test)\n",
    "print(f\"Accuracy of the DecisionTreeClassifier: {test_score:.1%}\")\n",
    "```\n",
    "\n",
    "\n",
    "Now we add the required code to track the experiment with MLflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fedeecaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started run f9248853f6b44f618ee82fe2d88aa5a8\n",
      "Load dataset...\n",
      "Prepare a train-test-split...\n",
      "Initialize and fit a DecisionTreeClassifier with max_depth=3, max_leaf_nodes4\n",
      "Result: Accuracy of the DecisionTreeClassifier: 96.5%\n"
     ]
    }
   ],
   "source": [
    "mlflow.set_experiment(exp_name)                         # <-- set the experiment we want to track to\n",
    "\n",
    "with mlflow.start_run() as run:                         # <-- start a run of the experiment\n",
    "    print(f\"Started run {run.info.run_id}\")\n",
    "    # Load dataset\n",
    "    print(\"Load dataset...\")\n",
    "    culmen_columns = [\"Culmen Length (mm)\", \"Culmen Depth (mm)\"]\n",
    "    target_column = \"Species\"\n",
    "\n",
    "    data_path = \"../data/penguins_classification.csv\"\n",
    "    data = pd.read_csv(data_path)\n",
    "\n",
    "    # Prepare a train-test-split\n",
    "    print(\"Prepare a train-test-split...\")\n",
    "    data, target = data[culmen_columns], data[target_column]\n",
    "    data_train, data_test, target_train, target_test = train_test_split(data, target, random_state=0)\n",
    "\n",
    "    # Initialize and fit a classifier\n",
    "    max_depth = 3\n",
    "    max_leaf_nodes = 4\n",
    "    print(f\"Initialize and fit a DecisionTreeClassifier with max_depth={max_depth}, max_leaf_nodes{max_leaf_nodes}\")\n",
    "    \n",
    "    mlflow.log_params(                                   # <-- Track parameters\n",
    "        {\"max_depth\": max_depth, \n",
    "         \"max_leaf_nodes\": max_leaf_nodes}\n",
    "    )\n",
    "    tree = DecisionTreeClassifier(\n",
    "        max_depth=max_depth,\n",
    "        max_leaf_nodes=max_leaf_nodes\n",
    "    )\n",
    "    tree.fit(data_train, target_train)\n",
    "\n",
    "    # Calculate test scores\n",
    "    test_score = tree.score(data_test, target_test)\n",
    "    mlflow.log_metric(\"test_accuracy\", test_score)       # <-- Track metrics\n",
    "    print(f\"Result: Accuracy of the DecisionTreeClassifier: {test_score:.1%}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "344a6d30",
   "metadata": {},
   "source": [
    "Have a look at the tracking UI to see how it played out!\n",
    "\n",
    "<img src='../img/mlflow_ui_pinguins_experiment_runs_list.png' alt='' width='1000'>\n",
    "\n",
    "<img src='../img/mlflow_ui_pinguins_experiment_first_run_details.png' alt='' width='1000'>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b28e17d",
   "metadata": {},
   "source": [
    "## 1.6. Exercise: track some more stuff"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a513541",
   "metadata": {},
   "source": [
    "What else could we want to track?\n",
    "\n",
    "Examples:  \n",
    "- Code Version: Git commit hash used for the run (if it was run from an MLflow Project)\n",
    "- Start & End Time: Start and end time of the run\n",
    "- Source: what code run?\n",
    "- Plots.\n",
    "- Properties of the input data\n",
    "- Model artifacts\n",
    "- ..."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0ac48edd",
   "metadata": {},
   "source": [
    "### Exercises: \n",
    "- Track the properties of the input data as parameters. (Hint: `data.shape[0]` gives the number of samples in a dataframe)\n",
    "- Track the notebook 'source code'. (Hint: `mlflow.log_artifact()` takes a path and copies the file to the artifact store.)\n",
    "\n",
    "We have so far:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2150c6bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory: /home/gustavo/training/Training.Docker/2.WebServices/6.MLFlow/Ex2_MLFlow_on_localhost_with_Dockerized_Tracking_Server/examples/palmer_pinguins/notebooks\n",
      "Started run 4bc89435c8f64d42af300213130e26f6\n",
      "Load dataset...\n",
      "Prepare a train-test-split...\n",
      "Initialize and fit a DecisionTreeClassifier with max_depth=3, max_leaf_nodes4\n",
      "Result: Accuracy of the DecisionTreeClassifier: 96.5%\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(f\"Current working directory: {os.getcwd()}\")\n",
    "\n",
    "# EXERCISE:\n",
    "\n",
    "mlflow.set_experiment(exp_name)                         # <-- set the experiment we want to track to\n",
    "\n",
    "with mlflow.start_run() as run:                         # <-- start a run of the experiment\n",
    "    print(f\"Started run {run.info.run_id}\")\n",
    "    # Load dataset\n",
    "    print(\"Load dataset...\")\n",
    "    culmen_columns = [\"Culmen Length (mm)\", \"Culmen Depth (mm)\"]\n",
    "    target_column = \"Species\"\n",
    "\n",
    "    data_path = \"../data/penguins_classification.csv\"\n",
    "    data = pd.read_csv(data_path)\n",
    "\n",
    "    # Prepare a train-test-split\n",
    "    print(\"Prepare a train-test-split...\")\n",
    "    data, target = data[culmen_columns], data[target_column]\n",
    "    data_train, data_test, target_train, target_test = train_test_split(data, target, random_state=0)\n",
    "\n",
    "    # Initialize and fit a classifier\n",
    "    max_depth = 3\n",
    "    max_leaf_nodes = 4\n",
    "    print(f\"Initialize and fit a DecisionTreeClassifier with max_depth={max_depth}, max_leaf_nodes{max_leaf_nodes}\")\n",
    "    \n",
    "    mlflow.log_params(                                  # <-- Track parameters\n",
    "        {\"max_depth\": max_depth, \n",
    "         \"max_leaf_nodes\": max_leaf_nodes}\n",
    "    )\n",
    "    tree = DecisionTreeClassifier(\n",
    "        max_depth=max_depth,\n",
    "        max_leaf_nodes=max_leaf_nodes\n",
    "    )\n",
    "    tree.fit(data_train, target_train)\n",
    "\n",
    "    # Calculate test scores\n",
    "    test_score = tree.score(data_test, target_test)\n",
    "    mlflow.log_metric(\"test_accuracy\", test_score)      # <-- Track metrics\n",
    "    print(f\"Result: Accuracy of the DecisionTreeClassifier: {test_score:.1%}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3c12e23d",
   "metadata": {},
   "source": [
    "Proposed exercice solution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a39f8f12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory: /home/gustavo/training/Training.Docker/2.WebServices/6.MLFlow/Ex2_MLFlow_on_localhost_with_Dockerized_Tracking_Server/examples/palmer_pinguins/notebooks\n",
      "Started run e34787a58bb64631a0406572e3d88b5a\n",
      "Load dataset...\n",
      "Prepare a train-test-split...\n",
      "Initialize and fit a DecisionTreeClassifier with max_depth=3, max_leaf_nodes4\n",
      "Current working directory: /home/gustavo/training/Training.Docker/2.WebServices/6.MLFlow/Ex2_MLFlow_on_localhost_with_Dockerized_Tracking_Server/examples/palmer_pinguins/notebooks\n",
      "Artifact Uri: /home/mlflowuser/mlruns/1/e34787a58bb64631a0406572e3d88b5a/artifacts\n",
      "Current working directory: /home/gustavo/training/Training.Docker/2.WebServices/6.MLFlow/Ex2_MLFlow_on_localhost_with_Dockerized_Tracking_Server\n"
     ]
    },
    {
     "ename": "PermissionError",
     "evalue": "[Errno 13] Permission denied: '/home/mlflowuser'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 52\u001b[0m\n\u001b[1;32m     50\u001b[0m os\u001b[39m.\u001b[39mchdir(\u001b[39m\"\u001b[39m\u001b[39m../../../\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     51\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mCurrent working directory: \u001b[39m\u001b[39m{\u001b[39;00mos\u001b[39m.\u001b[39mgetcwd()\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m---> 52\u001b[0m mlflow\u001b[39m.\u001b[39;49mlog_artifact(\u001b[39m\"\u001b[39;49m\u001b[39mexamples/palmer_pinguins/notebooks/1_Run_and_track_experiments.ipynb\u001b[39;49m\u001b[39m\"\u001b[39;49m) \u001b[39m# <-- ADDED: track the source code of the notebook\u001b[39;00m\n\u001b[1;32m     53\u001b[0m os\u001b[39m.\u001b[39mchdir(\u001b[39m\"\u001b[39m\u001b[39m./examples/palmer_pinguins/notebooks\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     54\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mCurrent working directory: \u001b[39m\u001b[39m{\u001b[39;00mos\u001b[39m.\u001b[39mgetcwd()\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/mlflow/lib/python3.10/site-packages/mlflow/tracking/fluent.py:776\u001b[0m, in \u001b[0;36mlog_artifact\u001b[0;34m(local_path, artifact_path)\u001b[0m\n\u001b[1;32m    753\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    754\u001b[0m \u001b[39mLog a local file or directory as an artifact of the currently active run. If no run is\u001b[39;00m\n\u001b[1;32m    755\u001b[0m \u001b[39mactive, this method will create a new active run.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    773\u001b[0m \u001b[39m        mlflow.log_artifact(\"features.txt\")\u001b[39;00m\n\u001b[1;32m    774\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    775\u001b[0m run_id \u001b[39m=\u001b[39m _get_or_start_run()\u001b[39m.\u001b[39minfo\u001b[39m.\u001b[39mrun_id\n\u001b[0;32m--> 776\u001b[0m MlflowClient()\u001b[39m.\u001b[39;49mlog_artifact(run_id, local_path, artifact_path)\n",
      "File \u001b[0;32m~/miniconda3/envs/mlflow/lib/python3.10/site-packages/mlflow/tracking/client.py:1002\u001b[0m, in \u001b[0;36mMlflowClient.log_artifact\u001b[0;34m(self, run_id, local_path, artifact_path)\u001b[0m\n\u001b[1;32m    967\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mlog_artifact\u001b[39m(\u001b[39mself\u001b[39m, run_id, local_path, artifact_path\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    968\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    969\u001b[0m \u001b[39m    Write a local file or directory to the remote ``artifact_uri``.\u001b[39;00m\n\u001b[1;32m    970\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1000\u001b[0m \u001b[39m        is_dir: False\u001b[39;00m\n\u001b[1;32m   1001\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1002\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_tracking_client\u001b[39m.\u001b[39;49mlog_artifact(run_id, local_path, artifact_path)\n",
      "File \u001b[0;32m~/miniconda3/envs/mlflow/lib/python3.10/site-packages/mlflow/tracking/_tracking_service/client.py:439\u001b[0m, in \u001b[0;36mTrackingServiceClient.log_artifact\u001b[0;34m(self, run_id, local_path, artifact_path)\u001b[0m\n\u001b[1;32m    437\u001b[0m     artifact_repo\u001b[39m.\u001b[39mlog_artifacts(local_path, path_name)\n\u001b[1;32m    438\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 439\u001b[0m     artifact_repo\u001b[39m.\u001b[39;49mlog_artifact(local_path, artifact_path)\n",
      "File \u001b[0;32m~/miniconda3/envs/mlflow/lib/python3.10/site-packages/mlflow/store/artifact/local_artifact_repo.py:37\u001b[0m, in \u001b[0;36mLocalArtifactRepository.log_artifact\u001b[0;34m(self, local_file, artifact_path)\u001b[0m\n\u001b[1;32m     33\u001b[0m artifact_dir \u001b[39m=\u001b[39m (\n\u001b[1;32m     34\u001b[0m     os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39martifact_dir, artifact_path) \u001b[39mif\u001b[39;00m artifact_path \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39martifact_dir\n\u001b[1;32m     35\u001b[0m )\n\u001b[1;32m     36\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mexists(artifact_dir):\n\u001b[0;32m---> 37\u001b[0m     mkdir(artifact_dir)\n\u001b[1;32m     38\u001b[0m shutil\u001b[39m.\u001b[39mcopyfile(local_file, os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(artifact_dir, os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mbasename(local_file)))\n",
      "File \u001b[0;32m~/miniconda3/envs/mlflow/lib/python3.10/site-packages/mlflow/utils/file_utils.py:120\u001b[0m, in \u001b[0;36mmkdir\u001b[0;34m(root, name)\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mOSError\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    119\u001b[0m     \u001b[39mif\u001b[39;00m e\u001b[39m.\u001b[39merrno \u001b[39m!=\u001b[39m errno\u001b[39m.\u001b[39mEEXIST \u001b[39mor\u001b[39;00m \u001b[39mnot\u001b[39;00m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39misdir(target):\n\u001b[0;32m--> 120\u001b[0m         \u001b[39mraise\u001b[39;00m e\n\u001b[1;32m    121\u001b[0m \u001b[39mreturn\u001b[39;00m target\n",
      "File \u001b[0;32m~/miniconda3/envs/mlflow/lib/python3.10/site-packages/mlflow/utils/file_utils.py:117\u001b[0m, in \u001b[0;36mmkdir\u001b[0;34m(root, name)\u001b[0m\n\u001b[1;32m    115\u001b[0m target \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(root, name) \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m root\n\u001b[1;32m    116\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 117\u001b[0m     os\u001b[39m.\u001b[39;49mmakedirs(target)\n\u001b[1;32m    118\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mOSError\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    119\u001b[0m     \u001b[39mif\u001b[39;00m e\u001b[39m.\u001b[39merrno \u001b[39m!=\u001b[39m errno\u001b[39m.\u001b[39mEEXIST \u001b[39mor\u001b[39;00m \u001b[39mnot\u001b[39;00m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39misdir(target):\n",
      "File \u001b[0;32m~/miniconda3/envs/mlflow/lib/python3.10/os.py:215\u001b[0m, in \u001b[0;36mmakedirs\u001b[0;34m(name, mode, exist_ok)\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[39mif\u001b[39;00m head \u001b[39mand\u001b[39;00m tail \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m path\u001b[39m.\u001b[39mexists(head):\n\u001b[1;32m    214\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 215\u001b[0m         makedirs(head, exist_ok\u001b[39m=\u001b[39;49mexist_ok)\n\u001b[1;32m    216\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mFileExistsError\u001b[39;00m:\n\u001b[1;32m    217\u001b[0m         \u001b[39m# Defeats race condition when another thread created the path\u001b[39;00m\n\u001b[1;32m    218\u001b[0m         \u001b[39mpass\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/mlflow/lib/python3.10/os.py:215\u001b[0m, in \u001b[0;36mmakedirs\u001b[0;34m(name, mode, exist_ok)\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[39mif\u001b[39;00m head \u001b[39mand\u001b[39;00m tail \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m path\u001b[39m.\u001b[39mexists(head):\n\u001b[1;32m    214\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 215\u001b[0m         makedirs(head, exist_ok\u001b[39m=\u001b[39;49mexist_ok)\n\u001b[1;32m    216\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mFileExistsError\u001b[39;00m:\n\u001b[1;32m    217\u001b[0m         \u001b[39m# Defeats race condition when another thread created the path\u001b[39;00m\n\u001b[1;32m    218\u001b[0m         \u001b[39mpass\u001b[39;00m\n",
      "    \u001b[0;31m[... skipping similar frames: makedirs at line 215 (1 times)]\u001b[0m\n",
      "File \u001b[0;32m~/miniconda3/envs/mlflow/lib/python3.10/os.py:215\u001b[0m, in \u001b[0;36mmakedirs\u001b[0;34m(name, mode, exist_ok)\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[39mif\u001b[39;00m head \u001b[39mand\u001b[39;00m tail \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m path\u001b[39m.\u001b[39mexists(head):\n\u001b[1;32m    214\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 215\u001b[0m         makedirs(head, exist_ok\u001b[39m=\u001b[39;49mexist_ok)\n\u001b[1;32m    216\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mFileExistsError\u001b[39;00m:\n\u001b[1;32m    217\u001b[0m         \u001b[39m# Defeats race condition when another thread created the path\u001b[39;00m\n\u001b[1;32m    218\u001b[0m         \u001b[39mpass\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/mlflow/lib/python3.10/os.py:225\u001b[0m, in \u001b[0;36mmakedirs\u001b[0;34m(name, mode, exist_ok)\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[39mreturn\u001b[39;00m\n\u001b[1;32m    224\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 225\u001b[0m     mkdir(name, mode)\n\u001b[1;32m    226\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mOSError\u001b[39;00m:\n\u001b[1;32m    227\u001b[0m     \u001b[39m# Cannot rely on checking for EEXIST, since the operating system\u001b[39;00m\n\u001b[1;32m    228\u001b[0m     \u001b[39m# could give priority to other errors like EACCES or EROFS\u001b[39;00m\n\u001b[1;32m    229\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m exist_ok \u001b[39mor\u001b[39;00m \u001b[39mnot\u001b[39;00m path\u001b[39m.\u001b[39misdir(name):\n",
      "\u001b[0;31mPermissionError\u001b[0m: [Errno 13] Permission denied: '/home/mlflowuser'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(f\"Current working directory: {os.getcwd()}\")\n",
    "\n",
    "# POSSIBLE SOLUTION:\n",
    "\n",
    "mlflow.set_experiment(exp_name)                                                                 # <-- set the experiment we want to track to\n",
    "\n",
    "with mlflow.start_run() as run:                                                                 # <-- start a run of the experiment\n",
    "    print(f\"Started run {run.info.run_id}\")\n",
    "    # Load dataset\n",
    "    print(\"Load dataset...\")\n",
    "    culmen_columns = [\"Culmen Length (mm)\", \"Culmen Depth (mm)\"]\n",
    "    target_column = \"Species\"\n",
    "\n",
    "    data_path = \"../data/penguins_classification.csv\"\n",
    "    data = pd.read_csv(data_path)\n",
    "    mlflow.log_param(\"num_samples\", data.shape[0])                                              # <-- ADDED: track the number of samples in the dataset\n",
    "\n",
    "    # Prepare a train-test-split\n",
    "    print(\"Prepare a train-test-split...\")\n",
    "    data, target = data[culmen_columns], data[target_column]\n",
    "    data_train, data_test, target_train, target_test = train_test_split(\n",
    "        data, target, random_state=0)\n",
    "\n",
    "    # Initialize and fit a classifier\n",
    "    max_depth = 3\n",
    "    max_leaf_nodes = 4\n",
    "    print(f\"Initialize and fit a DecisionTreeClassifier with max_depth={max_depth}, max_leaf_nodes{max_leaf_nodes}\")\n",
    "    \n",
    "    mlflow.log_params(                                                                          # <-- Track parameters\n",
    "        {\"max_depth\": max_depth, \n",
    "         \"max_leaf_nodes\": max_leaf_nodes}\n",
    "    )\n",
    "    tree = DecisionTreeClassifier(\n",
    "        max_depth=max_depth,\n",
    "        max_leaf_nodes=max_leaf_nodes\n",
    "    )\n",
    "    tree.fit(data_train, target_train)\n",
    "\n",
    "    # Calculate test scores\n",
    "    test_score = tree.score(data_test, target_test)\n",
    "    mlflow.log_metric(\"test_accuracy\", test_score)                                              # <-- Track metrics\n",
    "\n",
    "    print(f\"Current working directory: {os.getcwd()}\")\n",
    "    # print(run.info)\n",
    "    print(f\"Artifact Uri: {run.info.artifact_uri}\")\n",
    "    #mlflow.log_artifact(\"./1_Run and track experiments.ipynb\")                                 # <-- ADDED: track the source code of the notebook\n",
    "\n",
    "    # Change the current working directory to the same path the tracking server was executed\n",
    "    os.chdir(\"../../../\")\n",
    "    print(f\"Current working directory: {os.getcwd()}\")\n",
    "    mlflow.log_artifact(\"examples/palmer_pinguins/notebooks/1_Run_and_track_experiments.ipynb\") # <-- ADDED: track the source code of the notebook\n",
    "    os.chdir(\"./examples/palmer_pinguins/notebooks\")\n",
    "    print(f\"Current working directory: {os.getcwd()}\")\n",
    "\n",
    "    print(f\"Result: Accuracy of the DecisionTreeClassifier: {test_score:.1%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9548fff0",
   "metadata": {},
   "source": [
    "## 1.7. Log the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cee84310",
   "metadata": {},
   "source": [
    "We want to store the model artifacts to reuse it for deployment or later experimentation.\n",
    "Since we used a scikit-learn model here, we can use the build-in module to store the model in sklearn format. \n",
    "\n",
    "```mlflow.sklearn.log_model(tree, \"model\")```\n",
    "\n",
    "There are buildin modules for all kind of types of models, as well as the possibility to specify a custom format. Even autologging is available!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98ca2b06",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.set_experiment(exp_name)                                                                 # <-- set the experiment we want to track to\n",
    "\n",
    "with mlflow.start_run() as run:                                                                 # <-- start a run of the experiment\n",
    "    print(f\"Started run {run.info.run_id}\")\n",
    "    # Load dataset\n",
    "    print(\"Load dataset...\")\n",
    "    culmen_columns = [\"Culmen Length (mm)\", \"Culmen Depth (mm)\"]\n",
    "    target_column = \"Species\"\n",
    "\n",
    "    data_path = \"../data/penguins_classification.csv\"\n",
    "    data = pd.read_csv(data_path)\n",
    "    mlflow.log_param(\"num_samples\", data.shape[0])                                              # <-- track the number of samples in the dataset\n",
    "\n",
    "    # Prepare a train-test-split\n",
    "    print(\"Prepare a train-test-split...\")\n",
    "    data, target = data[culmen_columns], data[target_column]\n",
    "    data_train, data_test, target_train, target_test = train_test_split(\n",
    "        data, target, random_state=0)\n",
    "\n",
    "    # Initialize and fit a classifier\n",
    "    max_depth = 3\n",
    "    max_leaf_nodes = 4\n",
    "    print(f\"Initialize and fit a DecisionTreeClassifier with max_depth={max_depth}, max_leaf_nodes{max_leaf_nodes}\")\n",
    "    \n",
    "    mlflow.log_params(                                                                          # <-- Track parameters\n",
    "        {\"max_depth\": max_depth, \n",
    "         \"max_leaf_nodes\": max_leaf_nodes}\n",
    "    )\n",
    "    tree = DecisionTreeClassifier(\n",
    "        max_depth=max_depth,\n",
    "        max_leaf_nodes=max_leaf_nodes\n",
    "    )\n",
    "    tree.fit(data_train, target_train)\n",
    "\n",
    "    # Calculate test scores\n",
    "    test_score = tree.score(data_test, target_test)\n",
    "    mlflow.log_metric(\"test_accuracy\", test_score)                                              # <-- Track metrics\n",
    "    print(f\"Result: Accuracy of the DecisionTreeClassifier: {test_score:.1%}\")\n",
    "    \n",
    "    # Change the current working directory to the same path the tracking server was executed\n",
    "    os.chdir(\"../../../\")\n",
    "    print(f\"Current working directory: {os.getcwd()}\")\n",
    "\n",
    "    # Log the model\n",
    "    mlflow.sklearn.log_model(tree, \"model\")                                                     # <-- Log the model\n",
    "\n",
    "    # Log artifacts\n",
    "    print(f\"Artifact Uri: {run.info.artifact_uri}\")\n",
    "    mlflow.log_artifact(\"examples/palmer_pinguins/notebooks/1_Run_and_track_experiments.ipynb\") # <-- track the source code of the notebook\n",
    "                        \n",
    "    os.chdir(\"./examples/palmer_pinguins/notebooks\")\n",
    "    print(f\"Current working directory: {os.getcwd()}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "35ae3dbc",
   "metadata": {},
   "source": [
    "Have a look at the tracking UI to see how it played out!\n",
    "\n",
    "<img src='../img/mlflow_ui_pinguins_experiment_runs_list_3_with_model.png' alt='' width='1000'>\n",
    "\n",
    "<img src='../img/mlflow_ui_pinguins_experiment_run_details_3_with_model.png' alt='' width='1000'>\n",
    "\n",
    "We can have a look to the MLmodel package created:\n",
    "\n",
    "<img src='../img/mlflow_ui_pinguins_experiment_run_details_3_with_model-MLmodel.png' alt='' width='1000'>\n",
    "\n",
    "The conda environment especification:\n",
    "\n",
    "<img src='../img/mlflow_ui_pinguins_experiment_run_details_3_with_model-Conda.png' alt='' width='1000'>\n",
    "\n",
    "And the python environment especification :\n",
    "\n",
    "<img src='../img/mlflow_ui_pinguins_experiment_run_details_3_with_model-PythonEnv.png' alt='' width='1000'>\n",
    "<img src='../img/mlflow_ui_pinguins_experiment_run_details_3_with_model-Requirements.png' alt='' width='1000'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4d31206",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercice: Run the experiment (in the above cell) with different model parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffcaf369",
   "metadata": {},
   "source": [
    "## 1.8. Compare models in the UI."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8461ec0c",
   "metadata": {},
   "source": [
    "## 1.9. Optional: Add a signature to the model\n",
    "\n",
    "Define what the model expects and enforce later in deployment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd07df45",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlflow.models.signature import ModelSignature\n",
    "from mlflow.types.schema import Schema, ColSpec\n",
    "\n",
    "input_schema = Schema([\n",
    "  ColSpec(\"double\", \"Culmen Length (mm)\"),\n",
    "  ColSpec(\"double\", \"Culmen Depth (mm)\"),\n",
    "])\n",
    "output_schema = Schema([ColSpec(\"string\")])\n",
    "\n",
    "signature = ModelSignature(inputs=input_schema, outputs=output_schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35afcf5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.set_experiment(exp_name)\n",
    "with mlflow.start_run() as run:\n",
    "    print(f\"Started run {run.info.run_id}\")\n",
    "    # Load dataset\n",
    "    print(\"Load dataset...\")\n",
    "    culmen_columns = [\"Culmen Length (mm)\", \"Culmen Depth (mm)\"]\n",
    "    target_column = \"Species\"\n",
    "\n",
    "    data_path = \"../data/penguins_classification.csv\"\n",
    "    data = pd.read_csv(data_path)\n",
    "    mlflow.log_param(\"num_samples\", data.shape[0])\n",
    "\n",
    "    # Prepare a train-test-split\n",
    "    print(\"Prepare a train-test-split...\")\n",
    "    data, target = data[culmen_columns], data[target_column]\n",
    "    data_train, data_test, target_train, target_test = train_test_split(\n",
    "        data, target, random_state=0)\n",
    "\n",
    "    # Initialize and fit a classifier\n",
    "    max_depth = 3\n",
    "    max_leaf_nodes = 4\n",
    "    print(f\"Initialize and fit a DecisionTreeClassifier with max_depth={max_depth}, max_leaf_nodes{max_leaf_nodes}\")\n",
    "    \n",
    "    mlflow.log_params(\n",
    "        {\"max_depth\": max_depth, \n",
    "         \"max_leaf_nodes\": max_leaf_nodes}\n",
    "    )\n",
    "    tree = DecisionTreeClassifier(\n",
    "        max_depth=max_depth,\n",
    "        max_leaf_nodes=max_leaf_nodes\n",
    "    )\n",
    "    tree.fit(data_train, target_train)\n",
    "\n",
    "    # Calculate test scores\n",
    "    test_score = tree.score(data_test, target_test)\n",
    "    mlflow.log_metric(\"test_accuracy\", test_score)                                              # <-- Track metrics\n",
    "    print(f\"Result: Accuracy of the DecisionTreeClassifier: {test_score:.1%}\")\n",
    "    \n",
    "\n",
    "    # Change the current working directory to the same path the tracking server was executed\n",
    "    os.chdir(\"../../../\")\n",
    "    print(f\"Current working directory: {os.getcwd()}\")\n",
    "\n",
    "    # Log the model\n",
    "    mlflow.sklearn.log_model(tree, \"model\", signature=signature)                                # <-- Now log the model with a signature\n",
    "\n",
    "    # Log artifacts\n",
    "    print(f\"Artifact Uri: {run.info.artifact_uri}\")\n",
    "    mlflow.log_artifact(\"examples/palmer_pinguins/notebooks/1_Run_and_track_experiments.ipynb\") # <-- track the source code of the notebook\n",
    "                        \n",
    "    os.chdir(\"./examples/palmer_pinguins/notebooks\")\n",
    "    print(f\"Current working directory: {os.getcwd()}\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "964627a1",
   "metadata": {},
   "source": [
    "We can now see how new our model, this time with a declared schema signature: \n",
    "\n",
    "<img src='../img/mlflow_ui_pinguins_experiment_run_details_4_with_model_with_signature.png' alt='' width='1000'>\n",
    "\n",
    "<img src='../img/mlflow_ui_pinguins_experiment_run_details_4_with_model_with_signature-MLmodel.png' alt='' width='1000'>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc8b7642",
   "metadata": {},
   "source": [
    "## 1.10. Use the model to predict locally"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9550aa26",
   "metadata": {},
   "source": [
    "Now we pick a model, retrieve it and make a prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7811d362",
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.chdir(\"/home/gustavo/training/Training.Docker/2.WebServices/6.MLFlow/Ex2_MLFlow_on_localhost_with_Dockerized_Tracking_Server//examples/palmer_pinguins/notebooks\")\n",
    "# print(f\"Current working directory: {os.getcwd()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70f86ddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the current working directory to the same path the tracking server was executed\n",
    "os.chdir(\"../../../\")\n",
    "print(f\"Current working directory: {os.getcwd()}\")\n",
    "\n",
    "logged_model = 'runs:/9112cae7ba4547f390029a8e93d9ffd6/model'\n",
    "\n",
    "# Load model as a Sklearn Model.\n",
    "loaded_model = mlflow.sklearn.load_model(logged_model)\n",
    "\n",
    "# Predict on a Pandas DataFrame.\n",
    "result=loaded_model.predict(pd.DataFrame(data_test))\n",
    "print(result)\n",
    "\n",
    "os.chdir(\"./examples/palmer_pinguins/notebooks\")\n",
    "# print(f\"Current working directory: {os.getcwd()}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlflow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "06edfb0a5c746fc39005b6ae5d5bc93de8214c7bd0d55b767355d186d7ff4fbb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
