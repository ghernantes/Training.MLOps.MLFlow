{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a2008fa7",
   "metadata": {},
   "source": [
    "# 1. Running and tracking machine learning experiments"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "36be61d6",
   "metadata": {},
   "source": [
    "## 1.0. The data we use: Palmer Pinguins\n",
    "\n",
    "Data were collected and made available by Dr. Kristen Gorman and the Palmer Station, Antarctica LTER, a member of the Long Term Ecological Research Network. It provides a great dataset for data exploration & visualization, as an alternative to iris.\n",
    "\n",
    "We will use this dataset in classification setting to predict the penguins’ species from anatomical information.\n",
    "\n",
    "Each penguin is from one of the three following species: Adelie, Gentoo, and Chinstrap.\n",
    "\n",
    "<!-- ![palmer penguins](../img/palmer_penguins.png \"Palmer Penguins\") -->\n",
    "<img src='../img/palmer_penguins.png' alt='' width='600'>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "706b6ce1",
   "metadata": {},
   "source": [
    "This problem is a classification problem since the target is categorical. We will use features based on penguins’ culmen measurement.\n",
    "\n",
    "<!-- ![Culmen features](../img/culmen_depth.png) -->\n",
    "<img src='../img/culmen_depth.png' alt='' width='600'>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1dee973",
   "metadata": {},
   "source": [
    "## 1.1. Load and prepare the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5501ff60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Culmen Length (mm)</th>\n",
       "      <th>Culmen Depth (mm)</th>\n",
       "      <th>Species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>212</th>\n",
       "      <td>46.2</td>\n",
       "      <td>14.9</td>\n",
       "      <td>Gentoo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253</th>\n",
       "      <td>47.2</td>\n",
       "      <td>15.5</td>\n",
       "      <td>Gentoo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>40.8</td>\n",
       "      <td>18.9</td>\n",
       "      <td>Adelie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>37.8</td>\n",
       "      <td>18.3</td>\n",
       "      <td>Adelie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>42.2</td>\n",
       "      <td>19.5</td>\n",
       "      <td>Adelie</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Culmen Length (mm)  Culmen Depth (mm) Species\n",
       "212                46.2               14.9  Gentoo\n",
       "253                47.2               15.5  Gentoo\n",
       "94                 40.8               18.9  Adelie\n",
       "19                 37.8               18.3  Adelie\n",
       "112                42.2               19.5  Adelie"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "culmen_columns = [\"Culmen Length (mm)\", \"Culmen Depth (mm)\"]\n",
    "target_column = \"Species\"\n",
    "\n",
    "data_path = \"../data/penguins_classification.csv\"\n",
    "data = pd.read_csv(data_path)\n",
    "\n",
    "data.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "757404bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "data, target = data[culmen_columns], data[target_column]\n",
    "data_train, data_test, target_train, target_test = train_test_split(data, target, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b33dd0e",
   "metadata": {},
   "source": [
    "## 1.2. The modelling: Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d9daa4c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeClassifier(max_depth=3, max_leaf_nodes=4)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier(max_depth=3, max_leaf_nodes=4)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "DecisionTreeClassifier(max_depth=3, max_leaf_nodes=4)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "tree = DecisionTreeClassifier(max_depth=3, max_leaf_nodes=4)\n",
    "tree.fit(data_train, target_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "55f76a53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the DecisionTreeClassifier: 96.5%\n"
     ]
    }
   ],
   "source": [
    "test_score = tree.score(data_test, target_test)\n",
    "print(f\"Accuracy of the DecisionTreeClassifier: {test_score:.1%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd3780fd",
   "metadata": {},
   "source": [
    "## 1.3. MLflow Stores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cded149",
   "metadata": {},
   "source": [
    "### Tracking stores\n",
    "\n",
    "MLflow supports two types of backend stores: file store and database-backed store.\n",
    "\n",
    "- Local file path (specified as file:/my/local/dir), where data is just directly stored locally. Defaults to `mlruns/`.\n",
    "- Database encoded as +://:<password>@:/. Mlflow supports the dialects mysql, mssql, sqlite, and postgresql. For more details, see SQLAlchemy database uri.\n",
    "- HTTP server (specified as https://my-server:5000), which is a server hosting an MLFlow tracking server.\n",
    "- Databricks workspace (specified as databricks or as databricks://, a Databricks CLI profile.)\n",
    "\n",
    "### Artifact stores\n",
    "Where you store models, plots and other stuff.\n",
    "\n",
    "- Amazon S3\n",
    "- Azure Blob Storage\n",
    "- Google Cloud Storage\n",
    "- FTP server\n",
    "- SFTP Server\n",
    "- NFS\n",
    "- HDFS"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "98893984",
   "metadata": {},
   "source": [
    "## 1.4. Setup and configure the tracking server (Scenario 3b)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "150febdf",
   "metadata": {},
   "source": [
    "We want to use a database as a tracking store and a local directory as artifact store.\n",
    "Using a database is required for later steps in the tutorial, like managing deployments. In this case, artifacts are stored under the local `./mlruns` directory, and MLflow entities are inserted in a SQLite database file `mflow.db`.\n",
    "\n",
    "Run to start the tracking server following the Scenario 3b:\n",
    "\n",
    "```\n",
    "mlflow server --backend-store-uri sqlite:///mflow.db --default-artifact-root mlruns/ --host 0.0.0.0 --port 5003\n",
    "```\n",
    "\n",
    "Now you should be able to see the Tracking UI in a browser at `http://localhost:5003`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a947eab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import mlflow.sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "447b5615",
   "metadata": {},
   "outputs": [],
   "source": [
    "server_uri = \"http://localhost:5003\"     # port 5003: a local tracking server \n",
    "#server_uri = \"http://localhost:5007\"     # port 5007: a local docker container running a tracking server\n",
    "\n",
    "mlflow.set_tracking_uri(server_uri)       # or set the MLFLOW_TRACKING_URI in the env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "36fa3afd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'http://localhost:5003'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlflow.tracking.get_tracking_uri()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e930ea21",
   "metadata": {},
   "source": [
    "### Create a new experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "21e087de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp_name = \"penguin_classification\"\n",
    "\n",
    "mlflow.create_experiment(exp_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77fc6a11",
   "metadata": {},
   "source": [
    "## 1.5. Add tracking code to the machine learning experiment above\n",
    "\n",
    "Basic things to track:\n",
    "- Parameters: Key-value input parameters: `mlflow.log_param, mlflow.log_params`\n",
    "- Metrics: Key-value metrics, where the value is numeric (can be updated over the run): `mlflow.log_metric, mlflow.log_metrics`"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0765bc20",
   "metadata": {},
   "source": [
    "Recall the following code from above:\n",
    "\n",
    "```python\n",
    "# Load dataset\n",
    "culmen_columns = [\"Culmen Length (mm)\", \"Culmen Depth (mm)\"]\n",
    "target_column = \"Species\"\n",
    "\n",
    "data_path = \"../data/penguins_classification.csv\"\n",
    "data = pd.read_csv(data_path)\n",
    "\n",
    "# Prepare a train-test-split\n",
    "data, target = data[culmen_columns], data[target_column]\n",
    "data_train, data_test, target_train, target_test = train_test_split(data, target, random_state=0)\n",
    "\n",
    "# Initialize and fit a classifier\n",
    "tree = DecisionTreeClassifier(max_depth=3, max_leaf_nodes=4)\n",
    "tree.fit(data_train, target_train)\n",
    "\n",
    "# Calculate test scores\n",
    "test_score = tree.score(data_test, target_test)\n",
    "print(f\"Accuracy of the DecisionTreeClassifier: {test_score:.1%}\")\n",
    "```\n",
    "\n",
    "\n",
    "Now we add the required code to track the experiment with MLflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fedeecaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started run d812ecae304e4df084a152f38e7023dd\n",
      "Load dataset...\n",
      "Prepare a train-test-split...\n",
      "Initialize and fit a DecisionTreeClassifier with max_depth=3, max_leaf_nodes4\n",
      "Result: Accuracy of the DecisionTreeClassifier: 96.5%\n"
     ]
    }
   ],
   "source": [
    "mlflow.set_experiment(exp_name)                         # <-- set the experiment we want to track to\n",
    "\n",
    "with mlflow.start_run() as run:                         # <-- start a run of the experiment\n",
    "    print(f\"Started run {run.info.run_id}\")\n",
    "    # Load dataset\n",
    "    print(\"Load dataset...\")\n",
    "    culmen_columns = [\"Culmen Length (mm)\", \"Culmen Depth (mm)\"]\n",
    "    target_column = \"Species\"\n",
    "\n",
    "    data_path = \"../data/penguins_classification.csv\"\n",
    "    data = pd.read_csv(data_path)\n",
    "\n",
    "    # Prepare a train-test-split\n",
    "    print(\"Prepare a train-test-split...\")\n",
    "    data, target = data[culmen_columns], data[target_column]\n",
    "    data_train, data_test, target_train, target_test = train_test_split(data, target, random_state=0)\n",
    "\n",
    "    # Initialize and fit a classifier\n",
    "    max_depth = 3\n",
    "    max_leaf_nodes = 4\n",
    "    print(f\"Initialize and fit a DecisionTreeClassifier with max_depth={max_depth}, max_leaf_nodes{max_leaf_nodes}\")\n",
    "    \n",
    "    mlflow.log_params(                                   # <-- Track parameters\n",
    "        {\"max_depth\": max_depth, \n",
    "         \"max_leaf_nodes\": max_leaf_nodes}\n",
    "    )\n",
    "    tree = DecisionTreeClassifier(\n",
    "        max_depth=max_depth,\n",
    "        max_leaf_nodes=max_leaf_nodes\n",
    "    )\n",
    "    tree.fit(data_train, target_train)\n",
    "\n",
    "    # Calculate test scores\n",
    "    test_score = tree.score(data_test, target_test)\n",
    "    mlflow.log_metric(\"test_accuracy\", test_score)       # <-- Track metrics\n",
    "    print(f\"Result: Accuracy of the DecisionTreeClassifier: {test_score:.1%}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "344a6d30",
   "metadata": {},
   "source": [
    "Have a look at the tracking UI to see how it played out!\n",
    "\n",
    "<img src='../img/mlflow_ui_pinguins_experiment_runs_list.png' alt='' width='1000'>\n",
    "\n",
    "<img src='../img/mlflow_ui_pinguins_experiment_first_run_details.png' alt='' width='1000'>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b28e17d",
   "metadata": {},
   "source": [
    "## 1.6. Exercise: track some more stuff"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a513541",
   "metadata": {},
   "source": [
    "What else could we want to track?\n",
    "\n",
    "Examples:  \n",
    "- Code Version: Git commit hash used for the run (if it was run from an MLflow Project)\n",
    "- Start & End Time: Start and end time of the run\n",
    "- Source: what code run?\n",
    "- Plots.\n",
    "- Properties of the input data\n",
    "- Model artifacts\n",
    "- ..."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0ac48edd",
   "metadata": {},
   "source": [
    "### Exercises: \n",
    "- Track the properties of the input data as parameters. (Hint: `data.shape[0]` gives the number of samples in a dataframe)\n",
    "- Track the notebook 'source code'. (Hint: `mlflow.log_artifact()` takes a path and copies the file to the artifact store.)\n",
    "\n",
    "We have so far:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2150c6bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory: /home/gustavo/training/GitHub/Training.MLOps.MLFlow/2_MLFlow_Backend_and_Artifact_Storage_Scenarios_1_2_and_3/examples/palmer_pinguins/notebooks\n",
      "Started run 41777d673b4c4000b0242fb9c0c94a12\n",
      "Load dataset...\n",
      "Prepare a train-test-split...\n",
      "Initialize and fit a DecisionTreeClassifier with max_depth=3, max_leaf_nodes4\n",
      "Result: Accuracy of the DecisionTreeClassifier: 96.5%\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(f\"Current working directory: {os.getcwd()}\")\n",
    "\n",
    "# EXERCISE:\n",
    "\n",
    "mlflow.set_experiment(exp_name)                         # <-- set the experiment we want to track to\n",
    "\n",
    "with mlflow.start_run() as run:                         # <-- start a run of the experiment\n",
    "    print(f\"Started run {run.info.run_id}\")\n",
    "    # Load dataset\n",
    "    print(\"Load dataset...\")\n",
    "    culmen_columns = [\"Culmen Length (mm)\", \"Culmen Depth (mm)\"]\n",
    "    target_column = \"Species\"\n",
    "\n",
    "    data_path = \"../data/penguins_classification.csv\"\n",
    "    data = pd.read_csv(data_path)\n",
    "\n",
    "    # Prepare a train-test-split\n",
    "    print(\"Prepare a train-test-split...\")\n",
    "    data, target = data[culmen_columns], data[target_column]\n",
    "    data_train, data_test, target_train, target_test = train_test_split(data, target, random_state=0)\n",
    "\n",
    "    # Initialize and fit a classifier\n",
    "    max_depth = 3\n",
    "    max_leaf_nodes = 4\n",
    "    print(f\"Initialize and fit a DecisionTreeClassifier with max_depth={max_depth}, max_leaf_nodes{max_leaf_nodes}\")\n",
    "    \n",
    "    mlflow.log_params(                                  # <-- Track parameters\n",
    "        {\"max_depth\": max_depth, \n",
    "         \"max_leaf_nodes\": max_leaf_nodes}\n",
    "    )\n",
    "    tree = DecisionTreeClassifier(\n",
    "        max_depth=max_depth,\n",
    "        max_leaf_nodes=max_leaf_nodes\n",
    "    )\n",
    "    tree.fit(data_train, target_train)\n",
    "\n",
    "    # Calculate test scores\n",
    "    test_score = tree.score(data_test, target_test)\n",
    "    mlflow.log_metric(\"test_accuracy\", test_score)      # <-- Track metrics\n",
    "    print(f\"Result: Accuracy of the DecisionTreeClassifier: {test_score:.1%}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3c12e23d",
   "metadata": {},
   "source": [
    "Proposed exercice solution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a39f8f12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory: /home/gustavo/training/GitHub/Training.MLOps.MLFlow/2_MLFlow_Backend_and_Artifact_Storage_Scenarios_1_2_and_3/examples/palmer_pinguins/notebooks\n",
      "Started run 6b45743850f24bcdaeb320c147fb1acf\n",
      "Load dataset...\n",
      "Prepare a train-test-split...\n",
      "Initialize and fit a DecisionTreeClassifier with max_depth=3, max_leaf_nodes4\n",
      "Current working directory temporaly moved to: /home/gustavo/training/GitHub/Training.MLOps.MLFlow/2_MLFlow_Backend_and_Artifact_Storage_Scenarios_1_2_and_3/mlflow\n",
      "Notebook '1_Run_and_track_experiments.ipynb' stored in: ./mlruns/1/6b45743850f24bcdaeb320c147fb1acf/artifacts\n",
      "Current working directory: /home/gustavo/training/GitHub/Training.MLOps.MLFlow/2_MLFlow_Backend_and_Artifact_Storage_Scenarios_1_2_and_3/examples/palmer_pinguins/notebooks\n",
      "Result: Accuracy of the DecisionTreeClassifier: 96.5%\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(f\"Current working directory: {os.getcwd()}\")\n",
    "\n",
    "# POSSIBLE SOLUTION:\n",
    "\n",
    "mlflow.set_experiment(exp_name)                                                                    # <-- set the experiment we want to track to\n",
    "\n",
    "with mlflow.start_run() as run:                                                                    # <-- start a run of the experiment\n",
    "    print(f\"Started run {run.info.run_id}\")\n",
    "    # Load dataset\n",
    "    print(\"Load dataset...\")\n",
    "    culmen_columns = [\"Culmen Length (mm)\", \"Culmen Depth (mm)\"]\n",
    "    target_column = \"Species\"\n",
    "\n",
    "    data_path = \"../data/penguins_classification.csv\"\n",
    "    data = pd.read_csv(data_path)\n",
    "    mlflow.log_param(\"num_samples\", data.shape[0])                                                 # <-- ADDED: track the number of samples in the dataset\n",
    "\n",
    "    # Prepare a train-test-split\n",
    "    print(\"Prepare a train-test-split...\")\n",
    "    data, target = data[culmen_columns], data[target_column]\n",
    "    data_train, data_test, target_train, target_test = train_test_split(\n",
    "        data, target, random_state=0)\n",
    "\n",
    "    # Initialize and fit a classifier\n",
    "    max_depth = 3\n",
    "    max_leaf_nodes = 4\n",
    "    print(f\"Initialize and fit a DecisionTreeClassifier with max_depth={max_depth}, max_leaf_nodes{max_leaf_nodes}\")\n",
    "    \n",
    "    mlflow.log_params(                                                                             # <-- Track parameters\n",
    "        {\"max_depth\": max_depth, \n",
    "         \"max_leaf_nodes\": max_leaf_nodes}\n",
    "    )\n",
    "    tree = DecisionTreeClassifier(\n",
    "        max_depth=max_depth,\n",
    "        max_leaf_nodes=max_leaf_nodes\n",
    "    )\n",
    "    tree.fit(data_train, target_train)\n",
    "\n",
    "    # Calculate test scores\n",
    "    test_score = tree.score(data_test, target_test)\n",
    "    mlflow.log_metric(\"test_accuracy\", test_score)                                                 # <-- Track metrics\n",
    "\n",
    "    # Track artifacts:  \n",
    "    os.chdir(\"../../../mlflow\")                                                                    # Change the current working directory to the same path the tracking server was executed:\n",
    "    print(f\"Current working directory temporaly moved to: {os.getcwd()}\")\n",
    "\n",
    "    mlflow.log_artifact(\"../examples/palmer_pinguins/notebooks/1_Run_and_track_experiments.ipynb\") # <-- ADDED: track the source code of the notebook\n",
    "    print(f\"Notebook '1_Run_and_track_experiments.ipynb' stored in: {run.info.artifact_uri}\")\n",
    "\n",
    "    os.chdir(\"../examples/palmer_pinguins/notebooks\")                                              # Change the current working directory to its original position         \n",
    "    print(f\"Current working directory: {os.getcwd()}\")\n",
    "\n",
    "    # Show results:\n",
    "    print(f\"Result: Accuracy of the DecisionTreeClassifier: {test_score:.1%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9548fff0",
   "metadata": {},
   "source": [
    "## 1.7. Log the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cee84310",
   "metadata": {},
   "source": [
    "We want to store the model artifacts to reuse it for deployment or later experimentation.\n",
    "Since we used a scikit-learn model here, we can use the build-in module to store the model in sklearn format. \n",
    "\n",
    "```mlflow.sklearn.log_model(tree, \"model\")```\n",
    "\n",
    "There are buildin modules for all kind of types of models, as well as the possibility to specify a custom format. Even autologging is available!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "98ca2b06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started run f7a63ac5ca554188a67636e3ed8007fe\n",
      "Load dataset...\n",
      "Prepare a train-test-split...\n",
      "Initialize and fit a DecisionTreeClassifier with max_depth=3, max_leaf_nodes4\n",
      "Result: Accuracy of the DecisionTreeClassifier: 96.5%\n",
      "Current working directory temporaly moved to: /home/gustavo/training/GitHub/Training.MLOps.MLFlow/2_MLFlow_Backend_and_Artifact_Storage_Scenarios_1_2_and_3/mlflow\n",
      "Notebook '1_Run_and_track_experiments.ipynb' stored in: ./mlruns/1/f7a63ac5ca554188a67636e3ed8007fe/artifacts\n",
      "Model stored in: ./mlruns/1/f7a63ac5ca554188a67636e3ed8007fe/artifacts/model\n",
      "Current working directory: /home/gustavo/training/GitHub/Training.MLOps.MLFlow/2_MLFlow_Backend_and_Artifact_Storage_Scenarios_1_2_and_3/examples/palmer_pinguins/notebooks\n"
     ]
    }
   ],
   "source": [
    "mlflow.set_experiment(exp_name)                                                                    # <-- set the experiment we want to track to\n",
    "\n",
    "with mlflow.start_run() as run:                                                                    # <-- start a run of the experiment\n",
    "    print(f\"Started run {run.info.run_id}\")\n",
    "    # Load dataset\n",
    "    print(\"Load dataset...\")\n",
    "    culmen_columns = [\"Culmen Length (mm)\", \"Culmen Depth (mm)\"]\n",
    "    target_column = \"Species\"\n",
    "\n",
    "    data_path = \"../data/penguins_classification.csv\"\n",
    "    data = pd.read_csv(data_path)\n",
    "    mlflow.log_param(\"num_samples\", data.shape[0])                                                 # <-- track the number of samples in the dataset\n",
    "\n",
    "    # Prepare a train-test-split\n",
    "    print(\"Prepare a train-test-split...\")\n",
    "    data, target = data[culmen_columns], data[target_column]\n",
    "    data_train, data_test, target_train, target_test = train_test_split(\n",
    "        data, target, random_state=0)\n",
    "\n",
    "    # Initialize and fit a classifier\n",
    "    max_depth = 3\n",
    "    max_leaf_nodes = 4\n",
    "    print(f\"Initialize and fit a DecisionTreeClassifier with max_depth={max_depth}, max_leaf_nodes{max_leaf_nodes}\")\n",
    "    \n",
    "    mlflow.log_params(                                                                             # <-- Track parameters\n",
    "        {\"max_depth\": max_depth, \n",
    "         \"max_leaf_nodes\": max_leaf_nodes}\n",
    "    )\n",
    "    tree = DecisionTreeClassifier(\n",
    "        max_depth=max_depth,\n",
    "        max_leaf_nodes=max_leaf_nodes\n",
    "    )\n",
    "    tree.fit(data_train, target_train)\n",
    "\n",
    "    # Calculate test scores\n",
    "    test_score = tree.score(data_test, target_test)\n",
    "    mlflow.log_metric(\"test_accuracy\", test_score)                                                 # <-- Track metrics\n",
    "    print(f\"Result: Accuracy of the DecisionTreeClassifier: {test_score:.1%}\")\n",
    "    \n",
    "    # Track artifacts \n",
    "    os.chdir(\"../../../mlflow\")                                                                    # Change the current working directory to the same path the tracking server was executed:\n",
    "    print(f\"Current working directory temporaly moved to: {os.getcwd()}\")\n",
    "\n",
    "    mlflow.log_artifact(\"../examples/palmer_pinguins/notebooks/1_Run_and_track_experiments.ipynb\") # <-- Track the source code of the notebook\n",
    "    print(f\"Notebook '1_Run_and_track_experiments.ipynb' stored in: {run.info.artifact_uri}\")\n",
    "\n",
    "    # Log the model\n",
    "    mlflow.sklearn.log_model(tree, \"model\")                                                        # <-- ADDED: Log the model\n",
    "    print(f\"Model stored in: {run.info.artifact_uri}/model\")\n",
    "\n",
    "    os.chdir(\"../examples/palmer_pinguins/notebooks\")                                              # Change the current working directory to its original position         \n",
    "    print(f\"Current working directory: {os.getcwd()}\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "35ae3dbc",
   "metadata": {},
   "source": [
    "Have a look at the tracking UI to see how it played out!\n",
    "\n",
    "<img src='../img/mlflow_ui_pinguins_experiment_runs_list_3_with_model.png' alt='' width='1000'>\n",
    "\n",
    "<img src='../img/mlflow_ui_pinguins_experiment_run_details_3_with_model.png' alt='' width='1000'>\n",
    "\n",
    "We can have a look to the MLmodel package created:\n",
    "\n",
    "<img src='../img/mlflow_ui_pinguins_experiment_run_details_3_with_model-MLmodel.png' alt='' width='1000'>\n",
    "\n",
    "The conda environment especification:\n",
    "\n",
    "<img src='../img/mlflow_ui_pinguins_experiment_run_details_3_with_model-Conda.png' alt='' width='1000'>\n",
    "\n",
    "And the python environment especification :\n",
    "\n",
    "<img src='../img/mlflow_ui_pinguins_experiment_run_details_3_with_model-PythonEnv.png' alt='' width='1000'>\n",
    "<img src='../img/mlflow_ui_pinguins_experiment_run_details_3_with_model-Requirements.png' alt='' width='1000'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4d31206",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercice: Run the experiment (in the above cell) with different model parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffcaf369",
   "metadata": {},
   "source": [
    "## 1.8. Compare models in the UI."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8461ec0c",
   "metadata": {},
   "source": [
    "## 1.9. Optional: Add a signature to the model\n",
    "\n",
    "Define what the model expects and enforce later in deployment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cd07df45",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlflow.models.signature import ModelSignature\n",
    "from mlflow.types.schema import Schema, ColSpec\n",
    "\n",
    "input_schema = Schema([\n",
    "  ColSpec(\"double\", \"Culmen Length (mm)\"),\n",
    "  ColSpec(\"double\", \"Culmen Depth (mm)\"),\n",
    "])\n",
    "output_schema = Schema([ColSpec(\"string\")])\n",
    "\n",
    "signature = ModelSignature(inputs=input_schema, outputs=output_schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "35afcf5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started run 8e0f51052f4648f99bece2c8ae6e55cc\n",
      "Load dataset...\n",
      "Prepare a train-test-split...\n",
      "Initialize and fit a DecisionTreeClassifier with max_depth=3, max_leaf_nodes4\n",
      "Result: Accuracy of the DecisionTreeClassifier: 96.5%\n",
      "Current working directory temporaly moved to: /home/gustavo/training/GitHub/Training.MLOps.MLFlow/2_MLFlow_Backend_and_Artifact_Storage_Scenarios_1_2_and_3/mlflow\n",
      "Notebook '1_Run_and_track_experiments.ipynb' stored in: ./mlruns/1/8e0f51052f4648f99bece2c8ae6e55cc/artifacts\n",
      "Model stored in: ./mlruns/1/8e0f51052f4648f99bece2c8ae6e55cc/artifacts/model\n",
      "Current working directory: /home/gustavo/training/GitHub/Training.MLOps.MLFlow/2_MLFlow_Backend_and_Artifact_Storage_Scenarios_1_2_and_3/examples/palmer_pinguins/notebooks\n"
     ]
    }
   ],
   "source": [
    "mlflow.set_experiment(exp_name)\n",
    "with mlflow.start_run() as run:\n",
    "    print(f\"Started run {run.info.run_id}\")\n",
    "    # Load dataset\n",
    "    print(\"Load dataset...\")\n",
    "    culmen_columns = [\"Culmen Length (mm)\", \"Culmen Depth (mm)\"]\n",
    "    target_column = \"Species\"\n",
    "\n",
    "    data_path = \"../data/penguins_classification.csv\"\n",
    "    data = pd.read_csv(data_path)\n",
    "    mlflow.log_param(\"num_samples\", data.shape[0])\n",
    "\n",
    "    # Prepare a train-test-split\n",
    "    print(\"Prepare a train-test-split...\")\n",
    "    data, target = data[culmen_columns], data[target_column]\n",
    "    data_train, data_test, target_train, target_test = train_test_split(\n",
    "        data, target, random_state=0)\n",
    "\n",
    "    # Initialize and fit a classifier\n",
    "    max_depth = 3\n",
    "    max_leaf_nodes = 4\n",
    "    print(f\"Initialize and fit a DecisionTreeClassifier with max_depth={max_depth}, max_leaf_nodes{max_leaf_nodes}\")\n",
    "    \n",
    "    mlflow.log_params(\n",
    "        {\"max_depth\": max_depth, \n",
    "         \"max_leaf_nodes\": max_leaf_nodes}\n",
    "    )\n",
    "    tree = DecisionTreeClassifier(\n",
    "        max_depth=max_depth,\n",
    "        max_leaf_nodes=max_leaf_nodes\n",
    "    )\n",
    "    tree.fit(data_train, target_train)\n",
    "\n",
    "    # Calculate test scores\n",
    "    test_score = tree.score(data_test, target_test)\n",
    "    mlflow.log_metric(\"test_accuracy\", test_score)                                                 # <-- Track metrics\n",
    "    print(f\"Result: Accuracy of the DecisionTreeClassifier: {test_score:.1%}\")\n",
    "\n",
    "    # Log artifacts \n",
    "    os.chdir(\"../../../mlflow\")                                                                    # Change the current working directory to the same path the tracking server was executed:\n",
    "    print(f\"Current working directory temporaly moved to: {os.getcwd()}\")\n",
    "\n",
    "    mlflow.log_artifact(\"../examples/palmer_pinguins/notebooks/1_Run_and_track_experiments.ipynb\") # <-- Track the source code of the notebook\n",
    "    print(f\"Notebook '1_Run_and_track_experiments.ipynb' stored in: {run.info.artifact_uri}\")\n",
    "\n",
    "    # Log the model\n",
    "    mlflow.sklearn.log_model(tree, \"model\", signature=signature)                                   # <-- ADDED: Now log the model with a signature\n",
    "    print(f\"Model stored in: {run.info.artifact_uri}/model\")\n",
    "\n",
    "    os.chdir(\"../examples/palmer_pinguins/notebooks\")                                              # Change the current working directory to its original position         \n",
    "    print(f\"Current working directory: {os.getcwd()}\")\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "964627a1",
   "metadata": {},
   "source": [
    "We can now see how new our model, this time with a declared schema signature: \n",
    "\n",
    "<img src='../img/mlflow_ui_pinguins_experiment_run_details_4_with_model_with_signature.png' alt='' width='1000'>\n",
    "\n",
    "<img src='../img/mlflow_ui_pinguins_experiment_run_details_4_with_model_with_signature-MLmodel.png' alt='' width='1000'>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc8b7642",
   "metadata": {},
   "source": [
    "## 1.10. Use the model to predict locally"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9550aa26",
   "metadata": {},
   "source": [
    "Now we pick a model, retrieve it and make a prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "70f86ddd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory temporaly moved to: /home/gustavo/training/GitHub/Training.MLOps.MLFlow/2_MLFlow_Backend_and_Artifact_Storage_Scenarios_1_2_and_3/mlflow\n",
      "['Adelie' 'Chinstrap' 'Adelie' 'Chinstrap' 'Adelie' 'Chinstrap' 'Gentoo'\n",
      " 'Adelie' 'Gentoo' 'Adelie' 'Adelie' 'Gentoo' 'Gentoo' 'Adelie' 'Adelie'\n",
      " 'Gentoo' 'Gentoo' 'Gentoo' 'Chinstrap' 'Adelie' 'Chinstrap' 'Adelie'\n",
      " 'Chinstrap' 'Gentoo' 'Adelie' 'Adelie' 'Gentoo' 'Chinstrap' 'Gentoo'\n",
      " 'Gentoo' 'Adelie' 'Adelie' 'Adelie' 'Gentoo' 'Gentoo' 'Adelie'\n",
      " 'Chinstrap' 'Gentoo' 'Chinstrap' 'Adelie' 'Adelie' 'Adelie' 'Adelie'\n",
      " 'Gentoo' 'Adelie' 'Adelie' 'Chinstrap' 'Gentoo' 'Gentoo' 'Chinstrap'\n",
      " 'Adelie' 'Adelie' 'Adelie' 'Adelie' 'Adelie' 'Adelie' 'Gentoo' 'Adelie'\n",
      " 'Adelie' 'Chinstrap' 'Adelie' 'Adelie' 'Adelie' 'Gentoo' 'Adelie'\n",
      " 'Adelie' 'Adelie' 'Gentoo' 'Adelie' 'Gentoo' 'Adelie' 'Chinstrap'\n",
      " 'Adelie' 'Adelie' 'Gentoo' 'Adelie' 'Chinstrap' 'Adelie' 'Adelie'\n",
      " 'Gentoo' 'Adelie' 'Gentoo' 'Chinstrap' 'Adelie' 'Chinstrap' 'Gentoo']\n",
      "Current working directory: /home/gustavo/training/GitHub/Training.MLOps.MLFlow/2_MLFlow_Backend_and_Artifact_Storage_Scenarios_1_2_and_3/examples/palmer_pinguins/notebooks\n"
     ]
    }
   ],
   "source": [
    "# Change the current working directory to the same path the tracking server was executed\n",
    "os.chdir(\"../../../mlflow\")                                                                    \n",
    "print(f\"Current working directory temporaly moved to: {os.getcwd()}\")\n",
    "\n",
    "# Use YOUR last run id:\n",
    "logged_model = 'runs:/8e0f51052f4648f99bece2c8ae6e55cc/model'\n",
    "\n",
    "# Load model as a Sklearn Model.\n",
    "loaded_model = mlflow.sklearn.load_model(logged_model)\n",
    "\n",
    "# Predict on a Pandas DataFrame.\n",
    "result=loaded_model.predict(pd.DataFrame(data_test))\n",
    "print(result)\n",
    "\n",
    "# Change the current working directory to its original position  \n",
    "os.chdir(\"../examples/palmer_pinguins/notebooks\")                                                     \n",
    "print(f\"Current working directory: {os.getcwd()}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlflow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "06edfb0a5c746fc39005b6ae5d5bc93de8214c7bd0d55b767355d186d7ff4fbb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
